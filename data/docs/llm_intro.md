# 大语言模型 (LLM) 介绍

大语言模型（Large Language Model，LLM）是一类基于深度学习的自然语言处理模型，具有数十亿甚至数万亿的参数。

## 发展历程

- 2017: Transformer 架构提出（Attention Is All You Need）
- 2018: GPT-1、BERT 发布
- 2019: GPT-2 发布
- 2020: GPT-3 发布（1750亿参数）
- 2022: ChatGPT 发布，引发 AI 热潮
- 2023: GPT-4、Claude、Gemini 等多模态模型

## 核心技术

### Transformer 架构
- 自注意力机制（Self-Attention）
- 多头注意力（Multi-Head Attention）
- 位置编码（Positional Encoding）

### 训练方法
- 预训练（Pre-training）：在大规模语料上无监督学习
- 微调（Fine-tuning）：在特定任务上有监督训练
- RLHF：基于人类反馈的强化学习

## 主要能力

1. 文本生成
2. 问答对话
3. 代码编写
4. 翻译
5. 摘要生成
6. 推理分析

## 代表模型

- OpenAI: GPT-4, GPT-4o
- Anthropic: Claude 3
- Google: Gemini, PaLM
- Meta: LLaMA
- 国内: 文心一言、通义千问、智谱GLM
